{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cda146-c820-4641-b34f-2b7b22c0a5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: NVIDIA H100 PCIe MIG 1g.10gb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1883c7d-c402-499f-8f4b-3a462d2135bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gptq'...\n",
      "remote: Enumerating objects: 158, done.\u001b[K\n",
      "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 158 (delta 67), reused 59 (delta 59), pack-reused 75 (from 1)\u001b[K\n",
      "Receiving objects: 100% (158/158), 274.63 KiB | 9.81 MiB/s, done.\n",
      "Resolving deltas: 100% (84/84), done.\n",
      "/home/mknell/gptq\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/IST-DASLab/gptq.git\n",
    "%cd gptq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74cfcf2-905c-49c7-bed3-507520e14f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/mknell/.local/lib/python3.10/site-packages (4.57.6)\n",
      "Collecting transformers\n",
      "  Downloading transformers-5.1.0-py3-none-any.whl (10.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets in /home/mknell/.local/lib/python3.10/site-packages (4.5.0)\n",
      "Requirement already satisfied: accelerate in /home/mknell/.local/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in /home/mknell/.local/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mknell/.local/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mknell/.local/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mknell/.local/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mknell/.local/lib/python3.10/site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/mknell/.local/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mknell/.local/lib/python3.10/site-packages (from transformers) (0.7.0)\n",
      "Collecting typer-slim\n",
      "  Downloading typer_slim-0.21.2-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/mknell/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Collecting huggingface-hub<2.0,>=1.3.0\n",
      "  Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.3/553.3 kB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/mknell/.local/lib/python3.10/site-packages (from datasets) (3.20.3)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/mknell/.local/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in /home/mknell/.local/lib/python3.10/site-packages (from datasets) (2025.10.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/mknell/.local/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: xxhash in /home/mknell/.local/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/mknell/.local/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/mknell/.local/lib/python3.10/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /home/mknell/.local/lib/python3.10/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: pandas in /home/mknell/.local/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/mknell/.local/lib/python3.10/site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: psutil in /home/mknell/.local/lib/python3.10/site-packages (from accelerate) (7.2.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/mknell/.local/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in /home/mknell/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mknell/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: certifi in /home/mknell/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2026.1.4)\n",
      "Requirement already satisfied: idna in /home/mknell/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/mknell/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/mknell/.local/lib/python3.10/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Collecting shellingham\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/mknell/.local/lib/python3.10/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mknell/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.6.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mknell/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.5.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: jinja2 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/mknell/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mknell/.local/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mknell/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mknell/.local/lib/python3.10/site-packages (from pandas->datasets) (2025.3)\n",
      "Collecting annotated-doc>=0.0.2\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting click>=8.0.0\n",
      "  Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: async-timeout<6.0,>=4.0 in /home/mknell/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/mknell/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mknell/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/mknell/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/mknell/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/mknell/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mknell/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mknell/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mknell/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mknell/.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/mknell/.local/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mknell/.local/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Installing collected packages: shellingham, click, annotated-doc, typer-slim, huggingface-hub, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.36.0\n",
      "    Uninstalling huggingface-hub-0.36.0:\n",
      "      Successfully uninstalled huggingface-hub-0.36.0\n",
      "\u001b[33m  WARNING: The scripts hf and tiny-agents are installed in '/home/mknell/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.6\n",
      "    Uninstalling transformers-4.57.6:\n",
      "      Successfully uninstalled transformers-4.57.6\n",
      "\u001b[33m  WARNING: The script transformers is installed in '/home/mknell/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed annotated-doc-0.0.4 click-8.3.1 huggingface-hub-1.4.1 shellingham-1.5.4 transformers-5.1.0 typer-slim-0.21.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers datasets accelerate sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e8e839-24d1-418c-ae39-445094a4acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers: 4.57.0\n",
      "huggingface_hub: 0.34.0\n"
     ]
    }
   ],
   "source": [
    "import transformers, huggingface_hub\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"huggingface_hub:\", huggingface_hub.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9392686-a526-44f6-b6a5-fb4146f9dee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.38.2\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface_hub==0.20.3\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers==0.15.2\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/mknell/.local/lib/python3.10/site-packages (from transformers==4.38.2) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mknell/.local/lib/python3.10/site-packages (from transformers==4.38.2) (2.2.6)\n",
      "Requirement already satisfied: filelock in /home/mknell/.local/lib/python3.10/site-packages (from transformers==4.38.2) (3.20.3)\n",
      "Requirement already satisfied: requests in /home/mknell/.local/lib/python3.10/site-packages (from transformers==4.38.2) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/mknell/.local/lib/python3.10/site-packages (from transformers==4.38.2) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mknell/.local/lib/python3.10/site-packages (from transformers==4.38.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mknell/.local/lib/python3.10/site-packages (from transformers==4.38.2) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mknell/.local/lib/python3.10/site-packages (from transformers==4.38.2) (2026.1.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mknell/.local/lib/python3.10/site-packages (from huggingface_hub==0.20.3) (4.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mknell/.local/lib/python3.10/site-packages (from huggingface_hub==0.20.3) (2025.10.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mknell/.local/lib/python3.10/site-packages (from requests->transformers==4.38.2) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mknell/.local/lib/python3.10/site-packages (from requests->transformers==4.38.2) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mknell/.local/lib/python3.10/site-packages (from requests->transformers==4.38.2) (2026.1.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mknell/.local/lib/python3.10/site-packages (from requests->transformers==4.38.2) (2.6.3)\n",
      "Installing collected packages: huggingface_hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface_hub 1.4.1\n",
      "    Uninstalling huggingface_hub-1.4.1:\n",
      "      Successfully uninstalled huggingface_hub-1.4.1\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/mknell/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.22.2\n",
      "    Uninstalling tokenizers-0.22.2:\n",
      "      Successfully uninstalled tokenizers-0.22.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 5.1.0\n",
      "    Uninstalling transformers-5.1.0:\n",
      "      Successfully uninstalled transformers-5.1.0\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/mknell/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 4.5.0 requires huggingface-hub<2.0,>=0.25.0, but you have huggingface-hub 0.20.3 which is incompatible.\n",
      "accelerate 1.12.0 requires huggingface_hub>=0.21.0, but you have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.20.3 tokenizers-0.15.2 transformers-4.38.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"transformers==4.38.2\" \"huggingface_hub==0.20.3\" \"tokenizers==0.15.2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45027563-39ff-44ee-b53e-b79074c59a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting huggingface_hub==0.26.5\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.8/447.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/mknell/.local/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mknell/.local/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (4.15.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/mknell/.local/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/mknell/.local/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (3.20.3)\n",
      "Requirement already satisfied: requests in /home/mknell/.local/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (2.32.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/mknell/.local/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (25.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mknell/.local/lib/python3.10/site-packages (from huggingface_hub==0.26.5) (2025.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mknell/.local/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.5) (2026.1.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mknell/.local/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.5) (2.6.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mknell/.local/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.5) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mknell/.local/lib/python3.10/site-packages (from requests->huggingface_hub==0.26.5) (3.11)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/mknell/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.26.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"huggingface_hub==0.26.5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6fbb1f-774c-431f-ab53-d1b49b672b19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01maccelerate\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtransformers:\u001b[39m\u001b[33m\"\u001b[39m, transformers.__version__)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mhuggingface_hub:\u001b[39m\u001b[33m\"\u001b[39m, huggingface_hub.__version__)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import transformers, huggingface_hub, datasets, accelerate\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"huggingface_hub:\", huggingface_hub.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"accelerate:\", accelerate.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd2265c-b0ba-4ec9-8b12-53d022769199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/bin/python\n",
      "3.12.12 | packaged by conda-forge | (main, Oct 13 2025, 14:34:15) [GCC 14.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95eca42b-3b27-4cb0-b1e8-7db174a6ec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/default/lib/python3.12/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/default/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/default/lib/python3.12/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/envs/default/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/conda/envs/default/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/envs/default/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /opt/conda/envs/default/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in ./.local/lib/python3.12/site-packages (from datasets) (0.34.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/default/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/default/lib/python3.12/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/envs/default/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/envs/default/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/default/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/default/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/envs/default/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/envs/default/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/default/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/default/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./.local/lib/python3.12/site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.12/site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/envs/default/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/envs/default/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/default/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/default/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/default/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/default/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/envs/default/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/default/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/default/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/default/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/envs/default/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/default/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/default/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/default/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/default/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/default/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/default/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/default/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/default/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.5.0-py3-none-any.whl (515 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [datasets]\u001b[33m  WARNING: The script datasets-cli is installed in '/home/mknell/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed datasets-4.5.0 dill-0.4.0 multiprocess-0.70.18 pyarrow-23.0.0 xxhash-3.6.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U datasets accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41cc7d1-caae-4804-8151-e52c9f18c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: 4.5.0\n",
      "accelerate: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import datasets, accelerate\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"accelerate:\", accelerate.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd8e5bb5-5381-4e7b-947b-7f95cc907154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers: 4.57.0\n",
      "huggingface_hub: 0.34.0\n"
     ]
    }
   ],
   "source": [
    "import transformers, huggingface_hub\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"huggingface_hub:\", huggingface_hub.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37df853b-3ebd-497a-93a1-40c073bc0ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mknell/gptq\n",
      "/home/mknell/gptq\n",
      "LICENSE    datautils.py  modelutils.py\tquant_cuda.cpp\t      test_kernel.py\n",
      "README.md  gptq.py\t opt.py\t\tquant_cuda_kernel.cu  zeroShot\n",
      "bloom.py   llama.py\t quant.py\tsetup_cuda.py\n"
     ]
    }
   ],
   "source": [
    "%cd ~/gptq\n",
    "!pwd\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a67394b-b624-4756-aab2-f9db653fa0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mknell/gptq\n",
      "CUDA extension not installed.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "config.json: 100%|█████████████████████████████| 651/651 [00:00<00:00, 4.85MB/s]\n",
      "pytorch_model.bin: 100%|█████████████████████| 251M/251M [00:03<00:00, 76.4MB/s]\n",
      "generation_config.json: 100%|███████████████████| 137/137 [00:00<00:00, 599kB/s]\n",
      "model.safetensors:   0%|                             | 0.00/251M [00:00<?, ?B/s]\n",
      "README.md: 41.1kB [00:00, 111MB/s]\n",
      "model.safetensors:  21%|████▏               | 53.1M/251M [00:01<00:04, 40.3MB/s]Traceback (most recent call last):\n",
      "  File \"/home/mknell/gptq/opt.py\", line 444, in <module>\n",
      "    dataloader, testloader = get_loaders(\n",
      "                             ^^^^^^^^^^^^\n",
      "  File \"/home/mknell/gptq/datautils.py\", line 175, in get_loaders\n",
      "    return get_c4(nsamples, seed, seqlen, model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/gptq/datautils.py\", line 56, in get_c4\n",
      "    traindata = load_dataset(\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1488, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1167, in load_dataset_builder\n",
      "    builder_instance: DatasetBuilder = builder_cls(\n",
      "                                       ^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/builder.py\", line 343, in __init__\n",
      "    self.config, self.config_id = self._create_builder_config(\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/builder.py\", line 530, in _create_builder_config\n",
      "    raise ValueError(\n",
      "ValueError: BuilderConfig 'allenai--c4' not found. Available: ['en', 'en.noblocklist', 'en.noclean', 'realnewslike', 'multilingual', 'af', 'am', 'ar', 'az', 'be', 'bg', 'bg-Latn', 'bn', 'ca', 'ceb', 'co', 'cs', 'cy', 'da', 'de', 'el', 'el-Latn', 'en-multi', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fil', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'ha', 'haw', 'hi', 'hi-Latn', 'hmn', 'ht', 'hu', 'hy', 'id', 'ig', 'is', 'it', 'iw', 'ja', 'ja-Latn', 'jv', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lb', 'lo', 'lt', 'lv', 'mg', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'ne', 'nl', 'no', 'ny', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'ru-Latn', 'sd', 'si', 'sk', 'sl', 'sm', 'sn', 'so', 'sq', 'sr', 'st', 'su', 'sv', 'sw', 'ta', 'te', 'tg', 'th', 'tr', 'uk', 'und', 'ur', 'uz', 'vi', 'xh', 'yi', 'yo', 'zh', 'zh-Latn', 'zu']\n",
      "model.safetensors: 100%|█████████████████████| 251M/251M [00:02<00:00, 86.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "%cd ~/gptq\n",
    "!CUDA_VISIBLE_DEVICES=0 python opt.py facebook/opt-125m c4 --wbits 4 --nsamples 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c39d3c-f11a-4d73-aa6f-f896fca8eac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mknell/gptq\n",
      "CUDA extension not installed.\n",
      "usage: opt.py [-h] [--seed SEED] [--nsamples NSAMPLES] [--percdamp PERCDAMP]\n",
      "              [--nearest] [--wbits {2,3,4,16}] [--trits]\n",
      "              [--groupsize GROUPSIZE] [--sym] [--save SAVE] [--load LOAD]\n",
      "              [--benchmark BENCHMARK] [--check] [--new-eval] [--faster-kernel]\n",
      "              [--act-order] [--static-groups]\n",
      "              model {wikitext2,ptb,c4}\n",
      "opt.py: error: unrecognized arguments: --dataset-config realnewslike\n"
     ]
    }
   ],
   "source": [
    "%cd ~/gptq\n",
    "!CUDA_VISIBLE_DEVICES=0 python opt.py facebook/opt-125m c4 --dataset-config realnewslike --wbits 4 --nsamples 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb65f648-ca5a-46dd-8852-1a17c41174d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mknell/gptq\n",
      "CUDA extension not installed.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "README.md: 10.5kB [00:00, 18.1MB/s]\n",
      "wikitext-2-raw-v1/test-00000-of-00001.pa(…): 100%|█| 733k/733k [00:00<00:00, 1.2\n",
      "wikitext-2-raw-v1/train-00000-of-00001.p(…): 100%|█| 6.36M/6.36M [00:00<00:00, 1\n",
      "wikitext-2-raw-v1/validation-00000-of-00(…): 100%|█| 657k/657k [00:00<00:00, 2.8\n",
      "Generating test split: 100%|█████| 4358/4358 [00:00<00:00, 427613.74 examples/s]\n",
      "Generating train split: 100%|█| 36718/36718 [00:00<00:00, 1148504.80 examples/s]\n",
      "Generating validation split: 100%|█| 3760/3760 [00:00<00:00, 746253.87 examples/\n",
      "tokenizer_config.json: 100%|███████████████████| 685/685 [00:00<00:00, 6.18MB/s]\n",
      "vocab.json: 899kB [00:00, 74.1MB/s]\n",
      "merges.txt: 456kB [00:00, 139MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 441/441 [00:00<00:00, 6.56MB/s]\n",
      "Starting ...\n",
      "Ready.\n",
      "0 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.89\n",
      "error 11856.408203125\n",
      "0 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.17\n",
      "error 200.22244262695312\n",
      "0 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 9026.955078125\n",
      "0 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 5.2415080070495605\n",
      "0 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 613.1079711914062\n",
      "0 fc2\n",
      "Quantizing ...\n",
      "time 0.66\n",
      "error 38.448875427246094\n",
      "1 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.41\n",
      "error 7013.23681640625\n",
      "1 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 199.779296875\n",
      "1 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 5238.134765625\n",
      "1 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 4.887484073638916\n",
      "1 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 2441.376953125\n",
      "1 fc2\n",
      "Quantizing ...\n",
      "time 0.64\n",
      "error 30.835195541381836\n",
      "2 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.42\n",
      "error 14588.96484375\n",
      "2 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 556.8326416015625\n",
      "2 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 11723.5087890625\n",
      "2 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 4.903746128082275\n",
      "2 fc1\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 2318.287109375\n",
      "2 fc2\n",
      "Quantizing ...\n",
      "time 0.65\n",
      "error 28.007156372070312\n",
      "3 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.41\n",
      "error 8977.0673828125\n",
      "3 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 758.9601440429688\n",
      "3 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 8608.78125\n",
      "3 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 5.450949668884277\n",
      "3 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 1583.51611328125\n",
      "3 fc2\n",
      "Quantizing ...\n",
      "time 0.66\n",
      "error 20.488357543945312\n",
      "4 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.42\n",
      "error 12530.4716796875\n",
      "4 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 949.107666015625\n",
      "4 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 11889.615234375\n",
      "4 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 6.9505510330200195\n",
      "4 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 2350.1689453125\n",
      "4 fc2\n",
      "Quantizing ...\n",
      "time 0.65\n",
      "error 51.912689208984375\n",
      "5 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.41\n",
      "error 13922.3515625\n",
      "5 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 824.9741821289062\n",
      "5 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 13278.818359375\n",
      "5 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 12.290712356567383\n",
      "5 fc1\n",
      "Quantizing ...\n",
      "time 0.17\n",
      "error 2077.643310546875\n",
      "5 fc2\n",
      "Quantizing ...\n",
      "time 0.65\n",
      "error 102.59457397460938\n",
      "6 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.42\n",
      "error 15180.67578125\n",
      "6 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 1119.28564453125\n",
      "6 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 13408.974609375\n",
      "6 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 17.727386474609375\n",
      "6 fc1\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 2106.5986328125\n",
      "6 fc2\n",
      "Quantizing ...\n",
      "time 0.66\n",
      "error 130.70086669921875\n",
      "7 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.42\n",
      "error 16600.7421875\n",
      "7 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 1230.010498046875\n",
      "7 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 14803.71484375\n",
      "7 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 24.869104385375977\n",
      "7 fc1\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 2622.7412109375\n",
      "7 fc2\n",
      "Quantizing ...\n",
      "time 0.61\n",
      "error 160.27606201171875\n",
      "8 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.41\n",
      "error 17461.19140625\n",
      "8 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 1801.838134765625\n",
      "8 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 16169.6640625\n",
      "8 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.17\n",
      "error 35.160728454589844\n",
      "8 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 3402.501708984375\n",
      "8 fc2\n",
      "Quantizing ...\n",
      "time 0.65\n",
      "error 257.76080322265625\n",
      "9 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.41\n",
      "error 18752.1640625\n",
      "9 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 1959.16650390625\n",
      "9 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 16190.46484375\n",
      "9 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 67.78956604003906\n",
      "9 fc1\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 4226.3203125\n",
      "9 fc2\n",
      "Quantizing ...\n",
      "time 0.63\n",
      "error 319.91363525390625\n",
      "10 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.41\n",
      "error 21488.31640625\n",
      "10 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 2417.846435546875\n",
      "10 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 16156.677734375\n",
      "10 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 78.37947082519531\n",
      "10 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 5262.66015625\n",
      "10 fc2\n",
      "Quantizing ...\n",
      "time 0.65\n",
      "error 532.4560546875\n",
      "11 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.41\n",
      "error 18565.62890625\n",
      "11 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 3272.37890625\n",
      "11 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 14907.3134765625\n",
      "11 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 162.62391662597656\n",
      "11 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 8011.0966796875\n",
      "11 fc2\n",
      "Quantizing ...\n",
      "time 0.61\n",
      "error 817.3155517578125\n",
      "41.588056325912476\n",
      "wikitext2\n",
      "Evaluating ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "30.311382293701172\n",
      "README.md: 4.21kB [00:00, 10.1MB/s]\n",
      "ptb_text_only.py: 6.50kB [00:00, 27.4MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mknell/gptq/opt.py\", line 469, in <module>\n",
      "    dataloader, testloader = get_loaders(\n",
      "                             ^^^^^^^^^^^^\n",
      "  File \"/home/mknell/gptq/datautils.py\", line 171, in get_loaders\n",
      "    return get_ptb(nsamples, seed, seqlen, model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/gptq/datautils.py\", line 34, in get_ptb\n",
      "    traindata = load_dataset('ptb_text_only', 'penn_treebank', split='train')\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1488, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1133, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1032, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 992, in dataset_module_factory\n",
      "    raise RuntimeError(f\"Dataset scripts are no longer supported, but found {filename}\")\n",
      "RuntimeError: Dataset scripts are no longer supported, but found ptb_text_only.py\n"
     ]
    }
   ],
   "source": [
    "%cd ~/gptq\n",
    "!CUDA_VISIBLE_DEVICES=0 python opt.py facebook/opt-125m wikitext2 --wbits 4 --nsamples 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02311f4f-ff33-4460-82dd-65a5ca2220a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Starting ...\n",
      "Ready.\n",
      "0 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.71\n",
      "error 11856.408203125\n",
      "0 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 200.22244262695312\n",
      "0 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 9026.955078125\n",
      "0 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 5.2415080070495605\n",
      "0 fc1\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 613.1079711914062\n",
      "0 fc2\n",
      "Quantizing ...\n",
      "time 0.67\n",
      "error 38.448875427246094\n",
      "1 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.42\n",
      "error 7013.23681640625\n",
      "1 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 199.779296875\n",
      "1 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 5238.134765625\n",
      "1 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 4.887484073638916\n",
      "1 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 2441.376953125\n",
      "1 fc2\n",
      "Quantizing ...\n",
      "time 0.66\n",
      "error 30.835195541381836\n",
      "2 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.41\n",
      "error 14588.96484375\n",
      "2 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 556.8326416015625\n",
      "2 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 11723.5087890625\n",
      "2 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 4.903746128082275\n",
      "2 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 2318.287109375\n",
      "2 fc2\n",
      "Quantizing ...\n",
      "time 0.65\n",
      "error 28.007156372070312\n",
      "3 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.40\n",
      "error 8977.0673828125\n",
      "3 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 758.9601440429688\n",
      "3 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 8608.78125\n",
      "3 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 5.450949668884277\n",
      "3 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 1583.51611328125\n",
      "3 fc2\n",
      "Quantizing ...\n",
      "time 0.62\n",
      "error 20.488357543945312\n",
      "4 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.40\n",
      "error 12530.4716796875\n",
      "4 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 949.107666015625\n",
      "4 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 11889.615234375\n",
      "4 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 6.9505510330200195\n",
      "4 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 2350.1689453125\n",
      "4 fc2\n",
      "Quantizing ...\n",
      "time 0.62\n",
      "error 51.912689208984375\n",
      "5 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.42\n",
      "error 13922.3515625\n",
      "5 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 824.9741821289062\n",
      "5 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 13278.818359375\n",
      "5 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 12.290712356567383\n",
      "5 fc1\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 2077.643310546875\n",
      "5 fc2\n",
      "Quantizing ...\n",
      "time 0.67\n",
      "error 102.59457397460938\n",
      "6 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.41\n",
      "error 15180.67578125\n",
      "6 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 1119.28564453125\n",
      "6 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 13408.974609375\n",
      "6 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 17.727386474609375\n",
      "6 fc1\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 2106.5986328125\n",
      "6 fc2\n",
      "Quantizing ...\n",
      "time 0.61\n",
      "error 130.70086669921875\n",
      "7 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.40\n",
      "error 16600.7421875\n",
      "7 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 1230.010498046875\n",
      "7 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 14803.71484375\n",
      "7 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 24.869104385375977\n",
      "7 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 2622.7412109375\n",
      "7 fc2\n",
      "Quantizing ...\n",
      "time 0.61\n",
      "error 160.27606201171875\n",
      "8 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.40\n",
      "error 17461.19140625\n",
      "8 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 1801.838134765625\n",
      "8 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 16169.6640625\n",
      "8 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 35.160728454589844\n",
      "8 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 3402.501708984375\n",
      "8 fc2\n",
      "Quantizing ...\n",
      "time 0.62\n",
      "error 257.76080322265625\n",
      "9 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.42\n",
      "error 18752.1640625\n",
      "9 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 1959.16650390625\n",
      "9 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 16190.46484375\n",
      "9 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.16\n",
      "error 67.78956604003906\n",
      "9 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 4226.3203125\n",
      "9 fc2\n",
      "Quantizing ...\n",
      "time 0.64\n",
      "error 319.91363525390625\n",
      "10 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.42\n",
      "error 21488.31640625\n",
      "10 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 2417.846435546875\n",
      "10 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.14\n",
      "error 16156.677734375\n",
      "10 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 78.37947082519531\n",
      "10 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 5262.66015625\n",
      "10 fc2\n",
      "Quantizing ...\n",
      "time 0.66\n",
      "error 532.4560546875\n",
      "11 self_attn.k_proj\n",
      "Quantizing ...\n",
      "time 0.42\n",
      "error 18565.62890625\n",
      "11 self_attn.v_proj\n",
      "Quantizing ...\n",
      "time 0.17\n",
      "error 3272.37890625\n",
      "11 self_attn.q_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 14907.3134765625\n",
      "11 self_attn.out_proj\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 162.62391662597656\n",
      "11 fc1\n",
      "Quantizing ...\n",
      "time 0.15\n",
      "error 8011.0966796875\n",
      "11 fc2\n",
      "Quantizing ...\n",
      "time 0.63\n",
      "error 817.3155517578125\n",
      "41.01441240310669\n",
      "wikitext2\n",
      "Evaluating ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "30.311382293701172\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python opt.py facebook/opt-125m wikitext2 --wbits 4 --nsamples 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62ab864-ce9b-4683-8a30-f7ccdcd4e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "wikitext2\n",
      "Evaluating ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "27.653947830200195\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python opt.py facebook/opt-125m wikitext2 --wbits 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abfc738f-383f-43eb-9451-4a6129d8e103",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_loaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataloader, testloader = \u001b[43mget_loaders\u001b[49m(args.dataset, nsamples=args.nsamples, seed=args.seed, model=args.model, seqlen=\u001b[32m512\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_loaders' is not defined"
     ]
    }
   ],
   "source": [
    "dataloader, testloader = get_loaders(args.dataset, nsamples=args.nsamples, seed=args.seed, model=args.model, seqlen=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e245e0-bd04-4f1c-b526-6ebe2472488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "usage: opt.py [-h] [--seed SEED] [--nsamples NSAMPLES] [--percdamp PERCDAMP]\n",
      "              [--nearest] [--wbits {2,3,4,16}] [--trits]\n",
      "              [--groupsize GROUPSIZE] [--sym] [--save SAVE] [--load LOAD]\n",
      "              [--benchmark BENCHMARK] [--check] [--new-eval] [--faster-kernel]\n",
      "              [--act-order] [--static-groups]\n",
      "              model {wikitext2,ptb,c4,mc4}\n",
      "opt.py: error: argument dataset: invalid choice: 'mc4-de' (choose from wikitext2, ptb, c4, mc4)\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python opt.py facebook/opt-125m mc4-de --wbits 16 --nsamples 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "690407a3-18f6-44d4-af81-290e758f83e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "README.md: 16.0kB [00:00, 60.7MB/s]\n",
      "mc4.py: 9.68kB [00:00, 47.2MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mknell/gptq/opt.py\", line 444, in <module>\n",
      "    dataloader, testloader = get_loaders(\n",
      "                             ^^^^^^^^^^^^\n",
      "  File \"/home/mknell/gptq/datautils.py\", line 250, in get_loaders\n",
      "    return get_mc4(nsamples, seed, seqlen, model, lang=lang)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/gptq/datautils.py\", line 176, in get_mc4\n",
      "    traindata = load_dataset(\"mc4\", lang, split=\"train\", streaming=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1488, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1133, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1032, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 992, in dataset_module_factory\n",
      "    raise RuntimeError(f\"Dataset scripts are no longer supported, but found {filename}\")\n",
      "RuntimeError: Dataset scripts are no longer supported, but found mc4.py\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python opt.py facebook/opt-125m mc4-de --wbits 16 --nsamples 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d57f805-9ed9-4360-bc85-d83136ae3cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mknell/gptq\n",
      "LICENSE      bloom.py\t   llama.py\t  quant.py\t\tsetup_cuda.py\n",
      "README.md    datautils.py  modelutils.py  quant_cuda.cpp\ttest_kernel.py\n",
      "__pycache__  gptq.py\t   opt.py\t  quant_cuda_kernel.cu\tzeroShot\n"
     ]
    }
   ],
   "source": [
    "%cd ~/gptq\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7abebb39-9bfa-420a-b6e2-1b5ecb4f0b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mknell/gptq\n",
      "/home/mknell/gptq\n",
      "opt.py\n"
     ]
    }
   ],
   "source": [
    "%cd ~/gptq\n",
    "!pwd\n",
    "!ls opt.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4372f345-2876-4c70-a2f7-369b073442a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mknell/gptq/opt.py\", line 444, in <module>\n",
      "    dataloader, testloader = get_loaders(\n",
      "                             ^^^^^^^^^^^^\n",
      "  File \"/home/mknell/gptq/datautils.py\", line 250, in get_loaders\n",
      "    return get_mc4(nsamples, seed, seqlen, model, lang=lang)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/gptq/datautils.py\", line 176, in get_mc4\n",
      "    traindata = load_dataset(\"mc4\", lang, split=\"train\", streaming=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1488, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1133, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 1032, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"/home/mknell/.local/lib/python3.12/site-packages/datasets/load.py\", line 992, in dataset_module_factory\n",
      "    raise RuntimeError(f\"Dataset scripts are no longer supported, but found {filename}\")\n",
      "RuntimeError: Dataset scripts are no longer supported, but found mc4.py\n"
     ]
    }
   ],
   "source": [
    "!python opt.py facebook/opt-125m mc4 --wbits 16 --nsamples 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983e13a9-5131-4dac-9179-243532e32086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mknell/gptq\n"
     ]
    }
   ],
   "source": [
    "%cd ~/gptq\n",
    "!ls -la | grep mc4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee2f869b-b9c7-422e-ab99-ee4459da07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f mc4.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731b4dac-9d35-4e13-8518-8fad185936d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'mc4' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset scripts are no longer supported, but found mc4.py",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ds = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmc4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mde\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(ds))[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m][:\u001b[32m300\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/datasets/load.py:1488\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[39m\n\u001b[32m   1483\u001b[39m verification_mode = VerificationMode(\n\u001b[32m   1484\u001b[39m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode.BASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode.ALL_CHECKS\n\u001b[32m   1485\u001b[39m )\n\u001b[32m   1487\u001b[39m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1488\u001b[39m builder_instance = \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/datasets/load.py:1133\u001b[39m, in \u001b[36mload_dataset_builder\u001b[39m\u001b[34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1132\u001b[39m     features = _fix_for_backward_compatible_features(features)\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m dataset_module = \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[38;5;66;03m# Get dataset builder class\u001b[39;00m\n\u001b[32m   1143\u001b[39m builder_kwargs = dataset_module.builder_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/datasets/load.py:1032\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[39m\n\u001b[32m   1027\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[32m   1028\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m   1029\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any data file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1030\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1031\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1032\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1034\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any data file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/datasets/load.py:992\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    985\u001b[39m     api.hf_hub_download(\n\u001b[32m    986\u001b[39m         repo_id=path,\n\u001b[32m    987\u001b[39m         filename=filename,\n\u001b[32m   (...)\u001b[39m\u001b[32m    990\u001b[39m         proxies=download_config.proxies,\n\u001b[32m    991\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m992\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset scripts are no longer supported, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n\u001b[32m    994\u001b[39m     \u001b[38;5;66;03m# Use the infos from the parquet export except in some cases:\u001b[39;00m\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data_dir \u001b[38;5;129;01mor\u001b[39;00m data_files \u001b[38;5;129;01mor\u001b[39;00m (revision \u001b[38;5;129;01mand\u001b[39;00m revision != \u001b[33m\"\u001b[39m\u001b[33mmain\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mRuntimeError\u001b[39m: Dataset scripts are no longer supported, but found mc4.py"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"mc4\", \"de\", split=\"train\", streaming=True, trust_remote_code=True)\n",
    "print(next(iter(ds))[\"text\"][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ccd2c-1191-4a7f-b598-1bb4749ef279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default *",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
